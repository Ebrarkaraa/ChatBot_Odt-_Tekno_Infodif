{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ebrarkaraa/ChatBot_Odt-_Tekno_Infodif/blob/main/Pytorch_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Aq8ZCOA7gDBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b97493e-807e-40e0-9bfb-b17122665597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':\"File ID here\"})   # replace the id with id of file you want to access\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KmFTdWXBNKhY"
      },
      "outputs": [],
      "source": [
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ddQDX1wQKYMQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def bag_of_words(tokenized_sentence, words):\n",
        "    \"\"\"\n",
        "    return bag of words array:\n",
        "    1 for each known word that exists in the sentence, 0 otherwise\n",
        "    example:\n",
        "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
        "    \"\"\"\n",
        "    # stem each word\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
        "    # initialize bag with 0 for each word\n",
        "    bag = np.zeros(len(words), dtype=np.float32)\n",
        "    for idx, w in enumerate(words):\n",
        "        if w in sentence_words: \n",
        "            bag[idx] = 1\n",
        "\n",
        "    return bag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nmRmUz8cft2I"
      },
      "outputs": [],
      "source": [
        "with open('intents.json', 'r') as f:\n",
        "    intents = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ExR7oOTaxP4n"
      },
      "outputs": [],
      "source": [
        "all_words=[]\n",
        "tags=[]\n",
        "xy=[]\n",
        "for intent in intents[\"intents\"]:\n",
        "  tag=intent['tag']\n",
        "  tags.append(tag)\n",
        "\n",
        "  for pattern in intent['patterns']:\n",
        "    w=tokenize(pattern)\n",
        "    all_words.extend(w)\n",
        "    xy.append((w,tag))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb-ehOyNxP1J",
        "outputId": "a0c5820f-6e2d-4f61-c2dc-5d42286b25eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 unique stmmed words\n"
          ]
        }
      ],
      "source": [
        "ignore_words=['?','.','!']\n",
        "all_words=[stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words=sorted(set(all_words))\n",
        "tags=sorted(set(tags))\n",
        "\n",
        "print(len(all_words), 'unique stmmed words')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rXsizdyyxPzE"
      },
      "outputs": [],
      "source": [
        "X_train=[]\n",
        "y_train=[]\n",
        "\n",
        "for (pattern_sentence,tag) in  xy:\n",
        "  bag=bag_of_words(pattern_sentence,all_words)\n",
        "  X_train.append(bag)\n",
        "  label=tags.index(tag)\n",
        "  y_train.append(label)\n",
        "\n",
        "X_train=np.array(X_train)\n",
        "y_train=np.array(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV2Xx8dM2H_t"
      },
      "source": [
        "\n",
        "## Creating our Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nzu2XD-5QhK1"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Btm83RGv2Z2s"
      },
      "outputs": [],
      "source": [
        "class ChatDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_train)\n",
        "        self.x_data = X_train\n",
        "        self.y_data = y_train\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvx0ZIXczbyd",
        "outputId": "8f38176c-e34a-4c67-8332-e1a97734933b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 7\n"
          ]
        }
      ],
      "source": [
        "num_epochs=1000\n",
        "batch_size=8\n",
        "learning_rate=0.001\n",
        "input_size=len(X_train[0])\n",
        "hidden_size=8\n",
        "output_size=len(tags)\n",
        "print(input_size, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xxTvxaVMzbwF"
      },
      "outputs": [],
      "source": [
        "dataset=ChatDataset()\n",
        "train_loader=DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True,num_workers=0)\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model=NeuralNet(input_size,hidden_size,output_size).to(device)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer= torch.optim.Adam(model.parameters(),lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0-HrT5tzboL",
        "outputId": "1b2f3e6c-512e-4374-ef54-2b40836c90a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 1.5745\n",
            "Epoch [200/1000], Loss: 0.0409\n",
            "Epoch [300/1000], Loss: 0.0749\n",
            "Epoch [400/1000], Loss: 0.0106\n",
            "Epoch [500/1000], Loss: 0.0119\n",
            "Epoch [600/1000], Loss: 0.0072\n",
            "Epoch [700/1000], Loss: 0.0052\n",
            "Epoch [800/1000], Loss: 0.0025\n",
            "Epoch [900/1000], Loss: 0.0022\n",
            "Epoch [1000/1000], Loss: 0.0007\n",
            "final loss: 0.0007\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "        words = words.to(device)\n",
        "        labels = labels.to(dtype=torch.long).to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(words)\n",
        "        # if y would be one-hot, we must apply\n",
        "        # labels = torch.max(labels, 1)[1]\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "print(f'final loss: {loss.item():.4f}')\n",
        "data = {\n",
        "\"model_state\": model.state_dict(),\n",
        "\"input_size\": input_size,\n",
        "\"hidden_size\": hidden_size,\n",
        "\"output_size\": output_size,\n",
        "\"all_words\": all_words,\n",
        "\"tags\": tags\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEh_7pnhzo3U",
        "outputId": "8f315b43-7332-48c7-eb48-4cb740e5f8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved\n"
          ]
        }
      ],
      "source": [
        "File=\"data.pth\"\n",
        "torch.save(data,File)\n",
        "\n",
        "print(\"saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NDnYNCDlzoz1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ErP6HoOSzow7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUnbnI4nzoa5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH52MJobTFEU"
      },
      "source": [
        "\n",
        "## Loading our Saved Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX0f_8TgPRqK",
        "outputId": "75b5b2ef-30cd-4c83-d4cb-4ad6973228ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with open('intents.json', 'r') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLOf1gRd2-YH"
      },
      "source": [
        "\n",
        " \n",
        "## Using the Chatbot:\n",
        "---\n",
        "Modelimiz Hazır. Şimdi nihayet sohbet botumuzla sohbet edeceğiz. Antrenman verilerimiz çok kısıtlı olduğu için sadece bir avuç konu hakkında sohbet edebiliyoruz. Chatbot'un genelleme/bilgisini artırmak için daha büyük bir veri kümesi üzerinde eğitebilirsiniz."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_VW-ktY2dj7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UWVWl8SckMjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_tGgw41THXL",
        "outputId": "743119fb-a751-413a-a6dc-01f83817368a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's chat! (type 'quit' to exit)\n",
            "You: hi\n",
            "Sergio: Hi there, what can I do for you?\n",
            "You: i want to but flowers\n",
            "Sergio: Our saplings are as follows; Kaymak plant:20$ Dağ Çileği plant:15$ Manolya plant:45$ Kafkas Rose plant: 50$\n",
            "You: how to care for seedlings?\n",
            "Sergio: Water and soil structure are important for its maintenance. irrigation It needs to be watered once a week in winter and twice a day in summer,The soil structure should also be moist manure soil.\n",
            "You: How long does delivery take?\n",
            "Sergio: Shipping takes 2-4 days\n",
            "You: Is the product refundable?\n",
            "Sergio: it is not possible to return, it is possible to change or return if the seedlings are broken.\n",
            "You: thanks\n",
            "Sergio: Any time!\n",
            "You: Bye\n",
            "Sergio: Bye! Come back again soon.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "bot_name = \"Sergio\"\n",
        "print(\"Let's chat! (type 'quit' to exit)\")\n",
        "while True:\n",
        "    # sentence = \"do you use credit cards?\"\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence == \"quit\":\n",
        "        break\n",
        "\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.75:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
        "    else:\n",
        "        print(f\"{bot_name}: I do not understand...\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GYZjq-Aw2dwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jXRNlyr3Fv5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jt3Igck2d09j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YmHiFdhjUc8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Lm2Wo7oljbLE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Pytorch_chatbot.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}